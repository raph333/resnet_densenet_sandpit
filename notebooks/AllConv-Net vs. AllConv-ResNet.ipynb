{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-mtkJnzYN-v"
   },
   "source": [
    "# The AllConv Net\n",
    "\n",
    "A parameter efficient ConvNet as baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205912,
     "status": "ok",
     "timestamp": 1550209651768,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "hYXkCVsoU8Hp",
    "outputId": "02c94329-6dcf-4f6e-8947-b63cd637f9eb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../models')\n",
    "import utils\n",
    "import all_conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213810,
     "status": "ok",
     "timestamp": 1550209659695,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "qL0JbD5qUGfx",
    "outputId": "bf6af0ef-2fdf-4802-b473-fda88f08a3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training batches: 704\n",
      "validation batches: 79\n",
      "test batches: 157\n",
      "batch size: 64\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "# values for normalisation\n",
    "channel_means = (0.5071, 0.4865, 0.4409)\n",
    "channel_standard_devs = (0.2673, 0.2564, 0.2762)\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_means, channel_standard_devs)\n",
    "])\n",
    "batchsize=64\n",
    "\n",
    "test_set = datasets.CIFAR100(data_dir, train=False, transform=transformation, download=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batchsize)\n",
    "\n",
    "rest = datasets.CIFAR100(data_dir, train=True, transform=transformation, download=True)\n",
    "train_loader, validation_loader = utils.train_validation_split(rest, fraction=0.1, batchsize=batchsize)\n",
    "\n",
    "print(f'training batches: {len(train_loader)}')\n",
    "print(f'validation batches: {len(validation_loader)}')\n",
    "print(f'test batches: {len(test_loader)}')\n",
    "print(f'batch size: {batchsize}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[x.shape for x, y in train_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[x.shape for x, y in validation_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdmDUgajjD2B"
   },
   "source": [
    "### Dimensions\n",
    "\n",
    "#### convolutional layer\n",
    "\n",
    "$$W_{output} = \\Bigl\\lfloor \\frac{W_{input} - F + 2*P}{S} \\Bigr\\rfloor+ 1$$\n",
    "\n",
    "#### pooling layer\n",
    "\n",
    "$$W_{output} = \\frac{W_{input} - F}{S} + 1$$\n",
    "\n",
    "with:  \n",
    "W: width\n",
    "F: filter width  \n",
    "P: padding  \n",
    "S: stride\n",
    "\n",
    "... same goes for height (images are quadratic anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213796,
     "status": "ok",
     "timestamp": 1550209659696,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "cbgjlQx_jGIx",
    "outputId": "16ee6ade-020d-4003-9695-adb3cdaee631"
   },
   "outputs": [],
   "source": [
    "#( (16 - 3 + 2*1 ) / 2 ) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU3P2K40sAtt"
   },
   "source": [
    "## The all-convolutional net\n",
    "\n",
    "From [\"Striving for Simplicity: The All Convolutional Net\" from Springenberg et. al](https://arxiv.org/abs/1412.6806). This architecture simply downsamples the input with a couple of convolutions as in regular convolutional nets. Then, it arrives at a number of channles that is equal to the number of classes. Taking the mean of each channel (a feature map of very small height and width) gives a vector of the same length as the number of classes - the same output as in a fully connected layer. In this implementation, this architecture has only ~0.3 million paramters when starting with 32 channels. Downsampling is done with stride=2 convolutions.\n",
    "\n",
    "It's easy to extend the architecture with optional residual shortcuts. This allows to compare the residual version with the non-residual version of the same net.\n",
    "\n",
    "Interesting, Adam doesn't work at all with this net. Hence, I use only SGD with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214175,
     "status": "ok",
     "timestamp": 1550209660133,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "zETqvK2stVXU",
    "outputId": "affc1e31-8827-47c9-c2af-258e4ae1eb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: all-convolution net\n",
      "parameters: 1.387044 million\n",
      "\n",
      "epoch\ttraining-CE\tvalidation-CE\tvalidation-accuracy (%)\n",
      "0\t4.57\t\t4.47\t\t12.50\n",
      "1\t4.47\t\t4.37\t\t0.00\n",
      "2\t4.40\t\t4.28\t\t0.00\n",
      "3\t4.32\t\t4.10\t\t12.50\n",
      "4\t4.24\t\t3.98\t\t0.00\n",
      "5\t4.17\t\t3.90\t\t0.00\n",
      "6\t4.11\t\t3.82\t\t0.00\n",
      "7\t4.05\t\t3.72\t\t0.00\n",
      "8\t3.97\t\t3.64\t\t0.00\n",
      "9\t3.92\t\t3.54\t\t0.00\n",
      "10\t3.87\t\t3.45\t\t12.50\n",
      "11\t3.80\t\t3.34\t\t25.00\n",
      "12\t3.75\t\t3.26\t\t12.50\n",
      "13\t3.69\t\t3.14\t\t12.50\n",
      "14\t3.64\t\t3.08\t\t12.50\n",
      "15\t3.60\t\t3.03\t\t25.00\n",
      "16\t3.54\t\t2.99\t\t25.00\n",
      "17\t3.51\t\t2.91\t\t12.50\n",
      "18\t3.44\t\t2.85\t\t12.50\n",
      "19\t3.41\t\t2.79\t\t25.00\n",
      "20\t3.38\t\t2.68\t\t12.50\n",
      "21\t3.32\t\t2.67\t\t25.00\n",
      "22\t3.28\t\t2.61\t\t25.00\n",
      "23\t3.26\t\t2.58\t\t25.00\n",
      "24\t3.24\t\t2.53\t\t25.00\n",
      "25\t3.20\t\t2.51\t\t25.00\n",
      "26\t3.16\t\t2.45\t\t25.00\n",
      "27\t3.14\t\t2.38\t\t25.00\n",
      "28\t3.10\t\t2.37\t\t25.00\n",
      "29\t3.09\t\t2.37\t\t37.50\n",
      "30\t3.06\t\t2.34\t\t25.00\n",
      "31\t3.03\t\t2.28\t\t50.00\n",
      "32\t3.00\t\t2.26\t\t37.50\n",
      "33\t2.98\t\t2.25\t\t50.00\n",
      "34\t2.97\t\t2.19\t\t25.00\n",
      "35\t2.94\t\t2.17\t\t37.50\n",
      "36\t2.92\t\t2.17\t\t50.00\n",
      "37\t2.91\t\t2.15\t\t50.00\n",
      "38\t2.88\t\t2.13\t\t37.50\n",
      "39\t2.86\t\t2.12\t\t37.50\n",
      "40\t2.86\t\t2.09\t\t25.00\n",
      "41\t2.84\t\t2.06\t\t25.00\n",
      "42\t2.81\t\t2.03\t\t12.50\n",
      "43\t2.80\t\t2.02\t\t50.00\n",
      "44\t2.78\t\t2.02\t\t37.50\n",
      "45\t2.79\t\t2.00\t\t25.00\n",
      "46\t2.75\t\t1.97\t\t25.00\n",
      "47\t2.72\t\t1.98\t\t25.00\n",
      "48\t2.74\t\t1.98\t\t25.00\n",
      "49\t2.72\t\t1.95\t\t25.00\n",
      "50\t2.71\t\t1.93\t\t37.50\n",
      "51\t2.71\t\t1.92\t\t25.00\n",
      "52\t2.68\t\t1.93\t\t50.00\n"
     ]
    }
   ],
   "source": [
    "print('MODEL: all-convolution net')\n",
    "net = all_conv_net.AllCNN(c=64, residuals=False)\n",
    "print(f'parameters: {utils.count_parameters(net, in_millions=True):.2f} million\\n')\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=0.1,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=0  #0.00002\n",
    "                           )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.75, patience=5, threshold=0.01, verbose=True)\n",
    "\n",
    "utils.train_model(net, train_loader, validation_loader, optimizer, scheduler, max_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIjrpeUeqj1N",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.plot_error_curves(utils.error_stats, error_name='cross-entropy loss')\n",
    "utils.test_set_evaluation(net.cuda(), test_loader, just_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird observation:  \n",
    "Validation error is consistently lower than training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The all convolutional ResNet\n",
    "\n",
    "Compare the above results with the same architecture (and the same optimization scheme) with the addition of residual shortcuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MODEL: all-convolution ResNet')\n",
    "net = all_conv_net.AllCNN(c=64, residuals=True)  # same net with residual shortcuts!\n",
    "print(f'parameters: {utils.count_parameters(net, in_millions=True):.2f} million\\n')\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=0.1,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=0  #0.00002\n",
    "                           )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.75, patience=5, threshold=0.01, verbose=True)\n",
    "\n",
    "utils.train_model(net, train_loader, validation_loader, optimizer, scheduler, max_epoch=500)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
