{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-mtkJnzYN-v"
   },
   "source": [
    "# The AllConv Net\n",
    "\n",
    "A parameter efficient ConvNet as baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205912,
     "status": "ok",
     "timestamp": 1550209651768,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "hYXkCVsoU8Hp",
    "outputId": "02c94329-6dcf-4f6e-8947-b63cd637f9eb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../models')\n",
    "\n",
    "import utils\n",
    "import all_conv_net\n",
    "\n",
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSFmF0NtxqzR"
   },
   "outputs": [],
   "source": [
    "# All functions for this notebook in one cell:\n",
    "\n",
    "def train_validation_split(dataset, fraction=0.1, batchsize=64):\n",
    "    \"\"\"\n",
    "    @ dataset: torvision dataset\n",
    "    return: training and validation set as DataLoaders\n",
    "    \"\"\"\n",
    "    n_val_batches = round(len(dataset) * fraction)\n",
    "    val_indices = choice(range(len(dataset)), size=n_val_batches, replace=False)\n",
    "    train_indices = [x for x in range(len(dataset)) if x not in val_indices]\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              sampler=SubsetRandomSampler(train_indices),\n",
    "                              batch_size=batchsize\n",
    "                              )\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            sampler=SubsetRandomSampler(val_indices),\n",
    "                            batch_size=batchsize\n",
    "                            )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def prediction_from_output(model_output: torch.Tensor):\n",
    "    \"\"\"\n",
    "    @ model_output: output from the last linear layer (the output is without\n",
    "                    softmax because softmax is included in CE-loss)\n",
    "    return: predictions as tensor of class-indices\n",
    "    \"\"\"\n",
    "    probabilities = nn.Softmax(dim=1)(model_output)\n",
    "    max_probs, predictions = probabilities.max(dim=1)  \n",
    "    return max_probs, predictions\n",
    "  \n",
    "\n",
    "def train_model(net, train, validation, optimizer, max_epoch=100):\n",
    "    \"\"\"\n",
    "    This function returns nothing. The parametes of @net are updated in-place\n",
    "    and the error statistics are written to a global variable. This allows to\n",
    "    stop the training at any point and still have the results.\n",
    "  \n",
    "    @ net: a defined model - can also be pretrained\n",
    "    @ train, test: DataLoaders of training- and test-set\n",
    "    @ max_epoch: stop training after this number of epochs\n",
    "    \"\"\"  \n",
    "    global error_stats  # to track error log even when training aborted\n",
    "    error_stats = []\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[x for x in range(1, max_epoch) if x % 20 == 0],\n",
    "        gamma=0.5  # decrease learning rate by half each step\n",
    "    )\n",
    "    net.cuda()\n",
    "  \n",
    "    print('epoch\\ttraining-CE\\tvalidation-CE\\tvalidation-accuracy (%)')\n",
    "    for epoch in range(max_epoch):\n",
    "        net.train()\n",
    "        training_loss = 0\n",
    "    \n",
    "        for images, labels in train:\n",
    "            labels = labels.cuda()\n",
    "            images = images.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # prediction and error:\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)  # loss of current batch\n",
    "            training_loss += loss.item()  # keep track of training error\n",
    "\n",
    "            # update parameters:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():  # no backpropagation necessary\n",
    "            validation_loss = 0\n",
    "            net.eval()\n",
    "\n",
    "            for images, labels in validation:\n",
    "                labels = labels.cuda()\n",
    "                images = images.cuda()\n",
    "\n",
    "                # prediction and error:\n",
    "                output = net(images)\n",
    "                loss = criterion(output, labels)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                predictions = prediction_from_output(output)[1]\n",
    "                accuracy = (predictions == labels).float().mean() * 100\n",
    "    \n",
    "        # convert to batch loss:\n",
    "        training_loss = training_loss / len(train)\n",
    "        validation_loss = validation_loss / len(validation)\n",
    "        scheduler.step(validation_loss)\n",
    "\n",
    "        torch.save(net.state_dict(), f'epoch{epoch}.pt')\n",
    "        error_stats.append( (training_loss, validation_loss) )\n",
    "        print('{}\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}'.format(\n",
    "            epoch, training_loss, validation_loss, accuracy)\n",
    "             )\n",
    "\n",
    "    \n",
    "def test_set_evaluation(net, test, just_print=False):\n",
    "    \"\"\"\n",
    "    Calculate cross-entropy loss (mean batch loss) and accuracy on the test-set\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    net.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test:\n",
    "            labels = labels.cuda()\n",
    "            images = images.cuda()\n",
    "\n",
    "            output = net(images)\n",
    "            batch_loss = criterion(output, labels)\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            predictions = prediction_from_output(output)[1]\n",
    "            batch_accuracy = (predictions == labels).float().mean() * 100\n",
    "    \n",
    "    mean_batch_loss = total_loss / len(test)\n",
    "    accuracy = batch_accuracy.mean()\n",
    "  \n",
    "    if just_print:\n",
    "        print('\\nEvaluation on the test-set:')\n",
    "        print(f'mean batch cross-entropy loss: {mean_batch_loss:.2f}')\n",
    "        print(f'accuracy: {accuracy:.2f}')\n",
    "        return None\n",
    "  \n",
    "    return mean_batch_loss, accuracy\n",
    "    \n",
    "\n",
    "def count_parameters(model, in_millions=False):\n",
    "    \"\"\"\n",
    "    Count number of parameters of @model\n",
    "    \"\"\"\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    if in_millions:\n",
    "        n_params = n_params / 1000000\n",
    "    return n_params\n",
    "\n",
    "\n",
    "def show_image(processed_image: torch.Tensor, means: tuple, stdevs: tuple):\n",
    "    \"\"\"\n",
    "    @ means / @ stdevs: per-channel values used for normalizing the raw images\n",
    "    Recalculate original image from @processed_image and display it.\n",
    "    \"\"\"\n",
    "    img = processed_image.clone()\n",
    "    for channel in (0, 1, 2):\n",
    "        img[channel, :, :] = img[channel, :, :] * stdevs[channel] + means[channel]\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.grid('off')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "def class_name(index: int) -> str:\n",
    "    \"\"\"\n",
    "    @ index: class-index between 0-99\n",
    "    return: class-name \n",
    "    \"\"\"\n",
    "    class_names = [\n",
    "      'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee',\n",
    "      'beetle','bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly',\n",
    "      'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee',\n",
    "      'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup',\n",
    "      'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl',\n",
    "      'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower',\n",
    "      'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle',\n",
    "      'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter',\n",
    "      'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate',\n",
    "      'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road',\n",
    "      'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper',\n",
    "      'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower',\n",
    "      'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger',\n",
    "      'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale',\n",
    "      'willow_tree', 'wolf', 'woman', 'worm'\n",
    "    ]\n",
    "    class_index2name = dict(enumerate(class_names))\n",
    "    return class_index2name.get(index, f'invalid class index: {index}')\n",
    "\n",
    "\n",
    "def predict_and_display(net, testset, n=10):\n",
    "    \"\"\"\n",
    "    Predict @n random examples from the test-set and show images + predictions\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    for i in choice(range(len(testset)), size=n):\n",
    "        image, label = test_set[i]\n",
    "        output = net(image.unsqueeze(0).cuda())\n",
    "        prob, pred = prediction_from_output(output.unsqueeze(0))\n",
    "        prob, pred = prob.item(), pred.item()\n",
    "        evaluation = 'correct' if pred == label else 'mistake'\n",
    "\n",
    "        plt.figure( figsize=(2, 2) )\n",
    "        print(f'\\ntruth: {label} | pred: {pred} | prob: {prob:.2f}')\n",
    "        print(f'{evaluation}: ({class_name(label)} vs. {class_name(pred)})')\n",
    "        show_image(image, means=channel_means, stdevs=channel_standard_devs)\n",
    "\n",
    "\n",
    "def plot_error_curves(errors_over_time: list, error_name='error'):\n",
    "    \"\"\"\n",
    "    @ errors_over_time: list of tuples: (training-error, validation-error)\n",
    "    \"\"\"\n",
    "    error_train, error_validation = zip(*errors_over_time)\n",
    "\n",
    "    plt.plot(range(len(error_train)), error_train)\n",
    "    plt.plot(range(len(error_validation)), error_validation)\n",
    "    plt.xticks(range(0, len(error_train) + 1, len(error_train) // 2))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('CE')\n",
    "    plt.legend(('training', 'validation'))\n",
    "    plt.title(f'{error_name} over time')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZ8Q3ozrWqtQ"
   },
   "source": [
    "## Load data and pre-process\n",
    "\n",
    "No sphisticated pre-processing was done in this project. The data was normalized as is best practice in computer vision. For each channel, it's mean and standard deviation were calculated (in an exploratory notebook). Then each channels was normalized by subtracting its mean and dividing by its standard deviation.\n",
    "\n",
    "CIFAR-100 consists of 50000 training images and 10000 test-images (could be split differntly of course but we went with the standard split). The performance on the test-set was of course only evaluated once for each model. The 50000 remaining images were split into 40000 for training and 10000 for measuring the validation loss after every training epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213810,
     "status": "ok",
     "timestamp": 1550209659695,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "qL0JbD5qUGfx",
    "outputId": "bf6af0ef-2fdf-4802-b473-fda88f08a3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "training batches: 704\n",
      "validation batches: 79\n",
      "test batches: 157\n",
      "batch size: 64\n"
     ]
    }
   ],
   "source": [
    "# values for normalisation\n",
    "channel_means = (0.5071, 0.4865, 0.4409)\n",
    "channel_standard_devs = (0.2673, 0.2564, 0.2762)\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_means, channel_standard_devs)\n",
    "])\n",
    "batchsize=64\n",
    "\n",
    "test_set = datasets.CIFAR100(data_dir, train=False, transform=transformation, download=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batchsize)\n",
    "\n",
    "rest = datasets.CIFAR100(data_dir, train=True, transform=transformation, download=True)\n",
    "train_loader, validation_loader = train_validation_split(rest, fraction=0.1, batchsize=batchsize)\n",
    "\n",
    "print(f'training batches: {len(train_loader)}')\n",
    "print(f'validation batches: {len(validation_loader)}')\n",
    "print(f'test batches: {len(test_loader)}')\n",
    "print(f'batch size: {batchsize}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdmDUgajjD2B"
   },
   "source": [
    "### Dimensions\n",
    "\n",
    "#### convolutional layer\n",
    "\n",
    "$$W_{output} = \\Bigl\\lfloor \\frac{W_{input} - F + 2*P}{S} \\Bigr\\rfloor+ 1$$\n",
    "\n",
    "#### pooling layer\n",
    "\n",
    "$$W_{output} = \\frac{W_{input} - F}{S} + 1$$\n",
    "\n",
    "with:  \n",
    "W: width\n",
    "F: filter width  \n",
    "P: padding  \n",
    "S: stride\n",
    "\n",
    "... same goes for height (images are quadratic anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213796,
     "status": "ok",
     "timestamp": 1550209659696,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "cbgjlQx_jGIx",
    "outputId": "16ee6ade-020d-4003-9695-adb3cdaee631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate convolutional-layer dimension:\n",
    "( (16 - 3 + 2*1 ) / 2 ) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU3P2K40sAtt"
   },
   "source": [
    "### The all-convolution net\n",
    "\n",
    "In search for a leaner architecture, we implemented the all-convolution net described in the paper \"Striving for Simplicity: The All Convolutional Net\" from Springenberg et. al. This architecture simply downsamples the input with a couple of convolutions as in regular convolutional nets. Then, it arrives at a number of channles that is equal to the number of classes. Taking the mean of each channel (a feature map of very small height / width) gives a vector of the same length as the number of classes - the same output as in a fully connected layer. In our implementation, this architecture has only ~0.3 million paramters when starting with 32 channels. As before, downsampling is done with stride=2 convolutions.\n",
    "\n",
    "We also added optional residual shortcuts to this network. Due to the small number of parameters, it is feasible to compare the residual version with the non-residual version of this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQYZIsjJ6XfX"
   },
   "outputs": [],
   "source": [
    "class AllCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    All-convolutional network (no fully connected layers) with low number of\n",
    "    parameters. Can be converted into a ResNet by 'residuals=True'\n",
    "    \"\"\"\n",
    "  \n",
    "    def conv3x3(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Basic 3x3 convolutional layer plus batch normalization\n",
    "        Note: no ReLU in layer (ReLU after addition of residual)\n",
    "        \"\"\"\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                      stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout2d(p=0.2)\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def __init__(self, c=32, n_classes=100, residuals=False):\n",
    "        \"\"\"\n",
    "        @ c: number of channels after first convolution\n",
    "        @ n_classes: number of target classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.residuals = residuals\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.conv1 = self.conv3x3(3,   c,   stride=1)\n",
    "        self.conv2 = self.conv3x3(c,   c,   stride=1)\n",
    "\n",
    "        self.conv3 = self.conv3x3(c,   c*2, stride=2)  # -> 16**2\n",
    "        self.conv4 = self.conv3x3(c*2, c*2, stride=1)\n",
    "        self.conv5 = self.conv3x3(c*2, c*2, stride=1)\n",
    "\n",
    "        self.conv6 = self.conv3x3(c*2, c*4, stride=2)  # -> 8**2\n",
    "        self.conv7 = self.conv3x3(c*4, c*4, stride=1)\n",
    "\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(c*4, c*4, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(c*4),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            self.relu\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        conv9: make 1 channel per class -> take average of each feature map\n",
    "        -> 100 real values: same as in fully connected output layer\n",
    "        \"\"\"\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(c*4, n_classes, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            self.relu,\n",
    "            nn.AvgPool2d(kernel_size=8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        res = int(self.residuals)  # True / False; if 0: residual becomes 0\n",
    "\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.relu(self.conv2(h) + h*res )\n",
    "\n",
    "        h = self.relu(self.conv3(h))  # -> 16**2\n",
    "        h = self.relu(self.conv4(h) + h*res )\n",
    "        h = self.relu(self.conv5(h) + h*res )\n",
    "\n",
    "        h = self.relu(self.conv6(h))  # -> 8**2\n",
    "        h = self.relu(self.conv7(h) + h*res )\n",
    "\n",
    "        h = self.relu(self.conv8(h) + h*res )\n",
    "        y = self.conv9(h).squeeze()\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "all_conv = AllCNN(c=64, residuals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214175,
     "status": "ok",
     "timestamp": 1550209660133,
     "user": {
      "displayName": "dense net",
      "photoUrl": "",
      "userId": "16658811603426351804"
     },
     "user_tz": -60
    },
    "id": "zETqvK2stVXU",
    "outputId": "affc1e31-8827-47c9-c2af-258e4ae1eb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: all-convolution net\n",
      "parameters: 1.387044 million\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MODEL: all-convolution net')\n",
    "print(f'parameters: {count_parameters(all_conv, in_millions=True)} million\\n')\n",
    "\n",
    "optimizer = torch.optim.SGD(all_conv.parameters(),\n",
    "                            lr=0.1,  # will be decreased by scheduler\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=0.00002\n",
    "                           )\n",
    "#train_model(all_conv, train_loader, validation_loader, optimizer, max_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIjrpeUeqj1N"
   },
   "outputs": [],
   "source": [
    "plot_error_curves(error_stats, error_name='cross-entropy loss')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
